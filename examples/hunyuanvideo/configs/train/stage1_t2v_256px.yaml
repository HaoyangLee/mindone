env:
  mode: 0
  jit_level: O0
  seed: 42
  distributed: False
  debug: False

model:
  name: "HYVideo-T/2-cfgdistill"
  in_channels: 16
  pretrained_model_path: ../../ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt # the path is relative to this config
  text_states_dim: 4096
  text_states_dim_2: 768
  enable_ms_amp: True
  amp_level: O2
  factor_kwargs:
    dtype: bf16
    use_conv2d_patchify: True
    attn_mode: flash
    use_recompute: True
    num_no_recompute: 0

vae:
  type: "884-16c-hy"
  precision: fp16
  tiling: False
  trainable: False

dataset:
  csv_path: CSV_PATH
  video_folder: VIDEO_FOLDER
  text_emb_folder: TEXT_EMB_FOLDER
  empty_text_emb: EMPTY_TEXT_EMB_PATH
  deterministic_sample: False
  text_drop_prob: 0.2
  target_size: [ 256, 256 ]
  sample_n_frames: 29
  apply_transforms_dataset: True
  vae_scale_factor: 0.476986  # must be the same to vae scaling_factor
  output_columns: [ "video", "prompt_embeds", "prompt_mask", "prompt_embeds_2" ]

dataloader:
  batch_size: 1
  shuffle: True
  num_workers_dataset: 4

train:
  steps: 30000
  output_path: ../../output/stage1_t2v_256px  # the path is relative to this config

  sequence_parallel:
    shards: 1

  lr_scheduler:
    name: constant
    lr: 5.0e-5
    warmup_steps: 1000

  lr_reduce_on_plateau:
    factor: 0.5
    patience: 50  # in the number of validation steps, i.e., valid.frequency * patience steps
    mode: min
    min_delta: 0.01
    min_lr: 1.0e-6

  optimizer:
    name: adamw_re
    eps: 1e-15
    betas: [ 0.9, 0.999 ]
    weight_decay: 0.0001

  loss_scaler:
    class_path: mindspore.nn.FixedLossScaleUpdateCell   # or DynamicLossScaleUpdateCell in FP16
    init_args:
      loss_scale_value: 1

  ema:
    ema_decay: 0.9999
    offloading: True

  settings:
    zero_stage: 0
    gradient_accumulation_steps: 1
    clip_grad: True
    clip_norm: 1.0

  save:
    ckpt_save_policy: latest_k
    monitor_metric: "eval_loss_smoothed"
    ckpt_save_interval: &save_interval 1000
    ckpt_max_keep: 10
    log_interval: 1
    save_ema_only: False
    record_lr: False

valid:
  sampling_steps: 10
  frequency: *save_interval  # train.save.ckpt_save_interval should be divisible by the frequency

  dataset:
    csv_path: CSV_PATH
    video_folder: VIDEO_FOLDER
    text_emb_folder: TEXT_EMB_FOLDER
    target_size: [ 256, 256 ]
    apply_transforms_dataset: True
    vae_scale_factor: 0.476986  # must be the same to vae scaling_factor
    output_columns:  [ "video", "prompt_embeds", "prompt_mask", "prompt_embeds_2" ]

  dataloader:
    batch_size: 1
    shuffle: False
    num_workers_dataset: 4
